{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "## We will be using Titan Embeddings Model To generate Embedding\n",
    "\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain_community.chat_models.bedrock import BedrockChat\n",
    "\n",
    "## Data Ingestion\n",
    "\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# Vector Embedding And Vector Store\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "## LLm Models\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Bedrock Clients\n",
    "bedrock=boto3.client(service_name=\"bedrock-runtime\")\n",
    "bedrock_embeddings=BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",client=bedrock)\n",
    "\n",
    "\n",
    "#Extract PDF Data\n",
    "def extract_pdf(filename):\n",
    "    reader = PdfReader(filename)\n",
    "    page = reader.pages[0]\n",
    "    return page.extract_text()\n",
    "\n",
    "## Data ingestion\n",
    "def data_ingestion(inp):\n",
    "    loader=PyPDFDirectoryLoader(inp)\n",
    "    documents=loader.load()\n",
    "\n",
    "    # - in our testing Character split works better with this PDF data set\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=200,\n",
    "                                                 chunk_overlap=20)\n",
    "    \n",
    "    docs=text_splitter.split_documents(documents)\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claude_llm():\n",
    "    ##create the Anthropic Model\n",
    "    llm=BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",client=bedrock,\n",
    "                model_kwargs={'max_tokens':1000})\n",
    "    \n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_as_chunk(pdf_path):\n",
    "    # Open the PDF file\\\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load_and_split()\n",
    "    all_text = \"\"\n",
    "    \n",
    "    # Iterate through the pages and extract text\n",
    "    for page in pages:\n",
    "        all_text += page.page_content\n",
    "    \n",
    "    # Create a Document object with the entire text\n",
    "    doc = Document(page_content=all_text)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_pdf_as_chunk(\"pdfs/Final draft Guidelines on ICT and security risk management.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | get_claude_llm()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch([docs], {\"max_concurrency\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a summary of the key points from the document:\\n\\n- The guidelines provide requirements for financial institutions on how to manage ICT and security risks. They integrate and expand upon previous guidelines on security measures for operational and security risks of payment services under PSD2.\\n\\n- The scope covers payment service providers for payment services, credit institutions for all activities, and investment firms for all activities. \\n\\n- Key areas covered include:\\n    - Governance and strategy for ICT and security risk management\\n    - Risk management framework to identify, assess, and mitigate ICT and security risks\\n    - Information security measures like logical security, physical security, operations security\\n    - ICT operations management \\n    - ICT project and change management\\n    - Business continuity management\\n    - Relationship management requirements for payment service users\\n\\n- The guidelines aim to be technology and methodology agnostic to allow flexibility. Implementation should be proportionate based on the institution's size, complexity and risk profile.\\n\\n- The guidelines replace and repeal the previous Guidelines on security measures for operational and security risks once they take effect on 30 June 2020.\\n\\nIn summary, the document provides harmonized requirements across the EU for how financial institutions should govern and manage their ICT and security risks in a proportionate manner.\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(docs, inp):\n",
    "    vectorstore_faiss=FAISS.from_documents(\n",
    "        docs,\n",
    "        bedrock_embeddings\n",
    "    )\n",
    "    vectorstore_faiss.save_local(f\"faiss_index_{inp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vector_store([Document(summaries[0])], 'ict_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = FAISS.load_local(\"faiss_index_ict_s\", bedrock_embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever\n",
    "retriever_inp = MultiVectorRetriever(\n",
    "    vectorstore=faiss_index,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in [docs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docs linked to summaries\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add\n",
    "retriever_inp.vectorstore.add_documents(summary_docs)\n",
    "retriever_inp.docstore.mset(list(zip(doc_ids, [docs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = load_pdf_as_chunk('B.pdf')\n",
    "user_question = reader.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_compliance = \"\"\"\n",
    "Imagine you are a compliance officer for a bank checking if policies and guidelines are being met.\n",
    "Check the sections of the following document on whether the policies are being met.\n",
    "<question>\n",
    "{question}\n",
    "</question\n",
    "\n",
    "The following are the poilicies to be checked against:\n",
    "<context>\n",
    "{context}\n",
    "</context\n",
    "\n",
    "Provide the summary of the non-compliant sections \n",
    "and a high level yes, no or partially compliant\n",
    "in tabular form with the summary of the non-compliant section in one column, \n",
    "yes or no in the other column and \n",
    "the high level reason of non compliance or partial compliance in less than 5 words. \n",
    "Also provide the detailed summary under the table with the non compliant or partially compliant \n",
    "sections with quoted reference and suggested change. \n",
    "Please refer only to the document. \n",
    "Please be formal in your response. \n",
    "Please avoid any biases.\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT1 = PromptTemplate(\n",
    "    template=prompt_template_compliance, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_llm(llm,vectorstore_faiss,query, PROMPT):\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "    answer=qa({\"query\":query})\n",
    "    return answer['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narenjhabakh/Desktop/aws bedrock/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I will provide a formal and unbiased response based solely on the document provided, without any biases.\\n\\nSummarizing non-compliance in tabular form:\\n\\nNon-Compliant Section Summary | Compliance Status | Reason (< 5 words)\\n-----------------------------|--------------------|-----------------------\\nNo specific sections identified as non-compliant | - | -\\n\\nBased on the feedback provided in the document, no specific sections are explicitly identified as non-compliant with the guidelines. The comments and responses focus on clarifications, suggestions for improvements, and requests for additional guidance, but there is no clear indication of any sections being outright non-compliant.\\n\\nDetailed Summary:\\n\\nThe document does not explicitly quote any sections as being non-compliant with the guidelines. The comments and responses primarily revolve around the following:\\n\\n1. Requests for clarification on specific terms, definitions, or requirements.\\n2. Suggestions for rewording or restructuring certain sections for better clarity or alignment with industry practices.\\n3. Recommendations for additional guidance or examples in certain areas.\\n4. Feedback on the level of prescriptiveness or flexibility in certain requirements.\\n5. Concerns about potential conflicts or overlap with other regulations or guidelines.\\n\\nHowever, there are no instances where a section or requirement is explicitly stated as non-compliant or inappropriate. The feedback aims to improve the guidelines, provide additional context, or ensure consistency with existing practices and regulations, rather than identifying outright non-compliance.\\n\\nIt is important to note that the absence of identified non-compliance does not necessarily mean that all sections are fully compliant. The feedback and responses indicate areas where further clarification, refinement, or alignment may be needed, but there is no explicit mention of sections that do not comply with the intended guidelines or regulations.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_llm(get_claude_llm(),faiss_index,user_question, PROMPT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
